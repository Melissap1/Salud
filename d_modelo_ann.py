# -*- coding: utf-8 -*-
"""d_Modelo_ANN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b5y1VVDhD-NUkSsGK0MrTGaIPtNFk-Od

# <font color='056938'> **Librerias** </font>
"""

!pip install keras-tuner

!pip install -q tensorflow

import sys
import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from google.colab import drive


#Red neuronal
from tensorflow import keras
import tensorflow as tf
from sklearn import metrics
from keras_tuner.tuners import RandomSearch
from tensorflow.keras import layers
from sklearn.metrics import accuracy_score
import keras_tuner as kt

drive.mount('/content/drive')
#Define la parte del directorio que quieres trabajar
path = "/content/drive/MyDrive/Mod2/Salud"

# Add the path to sys.path
sys.path.append(path)
os.chdir(path)

os.curdir

# Ruta al archivo
ruta = '/content/drive/MyDrive/Mod2/Salud/data/df_limpia.xlsx'

# Leer excel
df = pd.read_excel(ruta)
df

sys.path.append(path)

from b_preprocesamiento import preparar_datos #Importar función que contiene los datos de entrenamiento, test y validación

X_train, X_val, X_test, y_train, y_val, y_test = preparar_datos(df)

"""# <font color='056938'> **Redes neuronales** </font>

<font color='056938'> **1.Modelo Base: Red Neuronal Artificial (ANN)**</font>

Se selecciona una red neuronal artificial (ANN) como modelo base, ya que es especialmente adecuada para el manejo de datos tabulares.
"""

# Reproducción de resultados utilizando semilla aleatoria
keras.utils.set_random_seed(42)
# Definir la semilla para numpy
# Definir la semilla para el backend random
# Definir la semilla para python

tf.random.set_seed(42)

"""Se decide usar 128 como numero máximo de neuronas ya que los datos presentan una baja complejidad."""

# Definición de hiperparámetros iniciales

ann1 = keras.models.Sequential()
# Capa de entrada
ann1.add(keras.layers.Dense(128, input_dim=X_train.shape[1], activation='tanh'))
# Capas ocultas
ann1.add(keras.layers.Dense(64, activation='relu'))
ann1.add(keras.layers.Dense(32, activation='relu'))
# Capa de salida para clasificación binaria (activación sigmoide)
ann1.add(keras.layers.Dense(1, activation='sigmoid'))

# Resumen de la arquitectura y # total de parametros
ann1.summary()

"""El optimizador seleccionado es "adam" ya que combina las ventajas de los algoritmos de gradiente descendente con momento y RMSprop, adaptándose dinámicamente a la tasa de aprendizaje de cada parámetro. Además, se usa la función de perdida "binary_crossentropy", ya que es la que se debe usar para problemas de clasificación como es el caso. Como métrica de rendimiento, se utiliza "Accuracy", ya que proporciona una interpretación intuitiva de cuán bien el modelo clasifica correctamente los datos de prueba."""

# Compilación de la ANN1 (Optimización de la ANN)
ann1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Entrenamiento de la Red Neuronal
history = ann1.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val))

# Visualización de las curvas de error

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Variación de la función de pérdida ANN1')
plt.xlabel('Epochs - Tiempo de entrenamiento')
plt.ylabel('Loss')
plt.legend(['train', 'val'])
plt.show()

# Visualización de las curcas de la métrica: Accuracy

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy de la ANN1 base')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Entrenamiento', 'Validación'], loc = 'upper left')
plt

"""Dado a que se evidencia sobreajuste se realiza un modelo ANN2 donde se le aplicara regularización L2  y otro modelo ANN3 en el cual se le aplicara Dropout. Con el fin si se evidencia alguna mejora.

<font color='056938'> **2.Modelo ANN2 con Regularización L2**</font>

Se aplica una regularización L2 solo a la primera capa oculta con una tasa de regularización de 0.01.
"""

from tensorflow.keras import regularizers

ann2 = keras.models.Sequential()
# Capa de entrada
ann2.add(keras.layers.Dense(128, input_dim=X_train.shape[1], activation='tanh'))
# Capas ocultas
ann2.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l2=0.01)))
ann2.add(keras.layers.Dense(32, activation='relu'))
# Capa de salida para clasificación binaria (activación sigmoide)
ann2.add(keras.layers.Dense(1, activation='sigmoid'))

# Compilación de la ANN1 (Optimización de la ANN)
ann2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
# Entrenamiento de la Red Neuronal
history2 = ann2.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val))

# Visualización de las curvas de error

plt.plot(history2.history['loss'])
plt.plot(history2.history['val_loss'])
plt.title('Variación de la función de pérdida ANN2')
plt.xlabel('Epochs - Tiempo de entrenamiento')
plt.ylabel('Loss')
plt.legend(['train', 'val'])
plt.show()

# Visualización de las curcas de la métrica: Accuracy

plt.plot(history2.history['accuracy'])
plt.plot(history2.history['val_accuracy'])
plt.title('Accuracy de la ANN2')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Entrenamiento', 'Validación'], loc = 'upper left')
plt

"""<font color='056938'> **3.Modelo ANN3 con Dropout**</font>

Se aplicará Dropout con una tasa del 30% a la capa de entrada, debido a su mayor número de neuronas.

"""

ann3 = keras.models.Sequential()
# Capa de entrada
ann3.add(keras.layers.Dense(128, input_dim=X_train.shape[1], activation='tanh'))
#Dropout
ann3.add(keras.layers.Dropout(0.3))
# Capas ocultas
ann3.add(keras.layers.Dense(64, activation='relu'))
ann3.add(keras.layers.Dense(32, activation='relu'))
# Capa de salida para clasificación binaria (activación sigmoide)
ann3.add(keras.layers.Dense(1, activation='sigmoid'))

# Compilación de la ANN1 (Optimización de la ANN)
ann3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
# Entrenamiento de la Red Neuronal
history3 = ann3.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val))

# Visualización de las curvas de error

plt.plot(history3.history['loss'])
plt.plot(history3.history['val_loss'])
plt.title('Variación de la función de pérdida ANN3')
plt.xlabel('Epochs - Tiempo de entrenamiento')
plt.ylabel('Loss')
plt.legend(['train', 'val'])
plt.show()

# Visualización de las curcas de la métrica: Accuracy

plt.plot(history3.history['accuracy'])
plt.plot(history3.history['val_accuracy'])
plt.title('Accuracy de la ANN3')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Entrenamiento', 'Validación'], loc = 'upper left')
plt

"""<font color='056938'> **4.Modelo ANN4: Mejor modelo encontrado Utilizando Óptimización de hiperparámetros**</font>

La optimización del modelo se centró en la afinación de los hiperparámetros más influyentes en el rendimiento de la red neuronal: el número de neuronas por capa, las funciones de activación y la tasa de aprendizaje. Se exploraron diversas combinaciones de estos parámetros con el fin de identificar la configuración óptima. Considerando los resultados obtenidos en experimentos previos, se decidió no incluir técnicas de regularización adicionales como L2 o Dropout, y tampoco se decidio probar varias opciones de numeros de capas, dada a que en nuestro caso el problema a resolver no presenta una complejidad excesiva, por tanto se deja la arquitectura del modelo base.
"""

# Definir la función para construir el modelo
def build_model(hp):
    model = keras.models.Sequential()

    # Capa de entrada
    model.add(keras.layers.Dense(
        units=hp.Int('units_input', min_value=32, max_value=256, step=64),  # Número de neuronas
        activation=hp.Choice('activation_input', values=['relu', 'tanh']),  # Función de activación
        input_dim=X_train.shape[1]
    ))

    # Capa oculta 1
    model.add(keras.layers.Dense(
        units=hp.Int('units_hidden1', min_value=16, max_value=128, step=32),
        activation=hp.Choice('activation_hidden1', values=['relu', 'tanh'])
    ))

    # Capa oculta 2
    model.add(keras.layers.Dense(
        units=hp.Int('units_hidden2', min_value=8, max_value=64, step=16),
        activation=hp.Choice('activation_hidden2', values=['relu', 'tanh'])
    ))

    # Capa de salida
    model.add(keras.layers.Dense(1, activation='sigmoid'))  # Clasificación binaria

     # Definición del compilador con optimización del hiperparámetro lr
    hp_learning_rate = hp.Choice('learning_rate', values=[0.1, 0.01, 0.001, 0.0001])

    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),
        loss='binary_crossentropy',
        metrics=['accuracy']
        )

    return model

tuner = kt.RandomSearch(
    hypermodel=build_model,
    objective='val_accuracy',  # Métrica objetivo
    max_trials=5,  # Número máximo de combinaciones de hiperparámetros
    executions_per_trial=2,  # Número de ejecuciones por combinación
    directory='results_tuner',
    project_name='mujeres_diabetes'
)

# Ejecución de la búsqueda aleatoria
tuner.search(X_train, y_train, epochs = 15, validation_data = (X_val, y_val))

# Obtener los mejores hiperparámetros
best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]
print("Mejores hiperparámetros encontrados:")
print(best_hp.values)

"""Podemos evidenciar que los hiperparámetros encontrados generan un modelo no tan complejo, ya que el número de neuronas escogidas son valores de no maximo 64 neuronas. Por otro lado, la tasa de arendizaje de 0.001, sugiere que los ajustes en los pesos de la red se realizan de forma gradual y cuidadosa, lo cual ayuda a evitar el riesgo de sobreajuste."""

# Reconstruir el mejor modelo
best_ANN = tuner.get_best_models(num_models=1)[0]

## Ajuste de la red neuronal con hiperparámetros óptimos
history_4 = best_ANN.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))

# Visualización de las curvas de error
plt.plot(history_4.history['loss'])
plt.plot(history_4.history['val_loss'])
plt.title('Variación de la función de pérdida - best ANN')
plt.xlabel('Epochs - Tiempo de entrenamiento')
plt.ylabel('Loss')
plt.legend(['train', 'val'])
plt.show()

# Visualización de las curvas de Accuracy
plt.plot(history_4.history['accuracy'])
plt.plot(history_4.history['val_accuracy'])
plt.title('Variación del Accuracy - best ANN')
plt.xlabel('Epochs - Tiempo de entrenamiento')
plt.ylabel('Accuracy')
plt.legend(['train', 'val'])
plt.show()

"""Al analizar la **gráfica de la función de pérdida del mejor modelo de red neuronal (best ANN)**, observamos que a pesar de haber optimizado los hiperparámetros, la curva de validación muestra un aumento progresivo en lugar de disminuir a lo largo de las épocas. Este comportamiento indica que el modelo está sobreajustándose a los datos de entrenamiento, es decir, está memorizando los datos específicos del conjunto de entrenamiento en lugar de aprender las características generales que le permitan generalizar a nuevos datos.

De manera similar, la **gráfica de Accuracy del modelo** revela que, aunque la precisión en el conjunto de entrenamiento aumenta, la precisión en el conjunto de validación disminuye en las últimas épocas. Esta tendencia confirma el sobreajuste, ya que el modelo está obteniendo un rendimiento excelente en los datos que ya ha visto (conjunto de entrenamiento), pero su desempeño empeora significativamente en datos no vistos (conjunto de validación).

En resumen, los resultados obtenidos sugieren que la configuración actual de hiperparámetros y posiblemente la arquitectura de la red no son las más adecuadas para evitar el sobreajuste.

<font color='056938'> **5.Evaluación de los 4 modelos**</font>

Se evaluan los 4 modelos anteriamiente analizados, ya que en forma visual o grafica no se evidenció una mejora significativa de un modelo con otro. Por tanto, para escoger el mejor modelo se evaluan con respecto a los datos de prueba.
"""

test_loss_ann1, test_acc_ann1 = ann1.evaluate(X_test, y_test)
test_loss_ann2, test_acc_ann2 = ann2.evaluate(X_test, y_test)
test_loss_ann3, test_acc_ann3 = ann3.evaluate(X_test, y_test)
test_loss_ann4, test_acc_ann4 = best_ANN.evaluate(X_test, y_test)

# Crear un diccionario con los resultados
results = {
    'Model': ['Modelo Base (ann1)', 'Modelo con Regularization L2 (ann2)', 'Modelo con Dropout (ann3)', 'Modelo optimizado (best_ann)'],
    'Test Accuracy': [test_acc_ann1, test_acc_ann2, test_acc_ann3, test_acc_ann4],
    'Test Loss': [test_loss_ann1, test_loss_ann2, test_loss_ann3, test_loss_ann4]
}

# Crear un DataFrame a partir del diccionario
df_results = pd.DataFrame(results)

# Mostrar la tabla con los resultados
df_results

"""De acuerdo con los resultados obtenidos, el modelo **ANN3** con Dropout se destaca como el mejor candidato, presentando el menor error de prueba (test loss) y la mayor precisión de prueba (test accuracy) entre los modelos evaluados. Sin embargo, es importante señalar que el error de prueba sigue siendo considerablemente alto, superando el 50%. Este resultado sugiere que, aunque el modelo ANN3 es superior a los demás en este conjunto de datos, su capacidad para generalizar a nuevos datos no vistos podría ser limitada."""

#Guardar Modelo ganador
ann3.save('/content/drive/MyDrive/Mod2/Salud/salidas/best_model.keras')

"""<font color='056938'> **Análisis del modelo ganador**</font>"""

### cargar modelo

modelo_ganador=tf.keras.models.load_model('/content/drive/MyDrive/Mod2/Salud/salidas/best_model.keras')
test_loss, test_auc = modelo_ganador.evaluate(X_test, y_test)
print(f"\Mejor AUC on test set: {test_auc:.4f}")

####probabilidades en test #######

prob=modelo_ganador.predict(X_test)
sns.histplot(prob, legend=False, bins=30)
plt.title("Distribución de probabilidades en X_test")
plt.xlabel("Probabilidad de tener diabetes")

"""Se observaron agrupaciones de predicciones cercanas a 0 y a 1, lo que sugiere que el modelo tiene alta confianza en muchas de sus predicciones."""

### probabilidades en entrenamiento #####
prob1=modelo_ganador.predict(X_train)
sns.histplot(prob1, legend=False, bins=30)
plt.title("Distribución de probabilidades en X_train")
plt.xlabel("Probabilidad de tener diabetes")

"""Se observaron agrupaciones de predicciones cercanas a 0, lo que sugiere que el modelo tiene alta confianza en muchas de sus predicciones en los datos de entrenamento cuando no se tiene diabetes."""

#Priorizar la predicción de los diabeticos
threshold_diabetes=0.5

pred_train=(modelo_ganador.predict(X_train)>=threshold_diabetes).astype('int')
print(metrics.classification_report(y_train, pred_train))
cm=metrics.confusion_matrix(y_train,pred_train, labels=[0,1])
disp=metrics.ConfusionMatrixDisplay(cm,display_labels=['Normal', 'Diabetes'])
disp.plot()


pred_test=(modelo_ganador.predict(X_test)>=threshold_diabetes).astype('int')
print(metrics.classification_report(y_test, pred_test))
cm=metrics.confusion_matrix(y_test,pred_test, labels=[0,1])
disp=metrics.ConfusionMatrixDisplay(cm,display_labels=['Normal', 'Diabetes'])
disp.plot()

#Priorizar la predicción de los no diabeticos
threshold_no_diabetes=0.4

pred_train=(modelo_ganador.predict(X_train)<=threshold_no_diabetes).astype('int')
print(metrics.classification_report(y_train, pred_train))
cm=metrics.confusion_matrix(y_train,pred_train, labels=[0,1])
disp=metrics.ConfusionMatrixDisplay(cm,display_labels=['Diabetes', 'Normal'])
disp.plot()

pred_test=(modelo_ganador.predict(X_test)<=threshold_no_diabetes).astype('int')
print(metrics.classification_report(y_test, pred_test))
cm=metrics.confusion_matrix(y_test,pred_test, labels=[0,1])
disp=metrics.ConfusionMatrixDisplay(cm,display_labels=['Diabetes', 'Normal'])
disp.plot()

"""Se evidencia que si se prioriza la predicción automatica de los no diabeticos, solo predice automaticamente 8 personas, y el resto tocá examinarlos. Por tanto, se decide priorizar a los diabeticos.

Se realizan más pruebas con threshold_diabiates
"""

#Priorizar la predicción de los diabeticos
threshold_diab=0.4
pred_test=(modelo_ganador.predict(X_test)>=threshold_diab).astype('int')
print(metrics.classification_report(y_test, pred_test))
cm=metrics.confusion_matrix(y_test,pred_test, labels=[0,1])
disp=metrics.ConfusionMatrixDisplay(cm,display_labels=['Normal', 'Diabetes'])
disp.plot()

#Priorizar la predicción de los diabeticos
threshold_diab=0.6

pred_train=(modelo_ganador.predict(X_train)>=threshold_diab).astype('int')
print(metrics.classification_report(y_train, pred_train))
cm=metrics.confusion_matrix(y_train,pred_train, labels=[0,1])
disp=metrics.ConfusionMatrixDisplay(cm,display_labels=['Normal', 'Diabetes'])
disp.plot()


pred_test=(modelo_ganador.predict(X_test)>=threshold_diab).astype('int')
print(metrics.classification_report(y_test, pred_test))
cm=metrics.confusion_matrix(y_test,pred_test, labels=[0,1])
disp=metrics.ConfusionMatrixDisplay(cm,display_labels=['Normal', 'Diabetes'])
disp.plot()

prob = modelo_ganador.predict(X_test).ravel()

thresholds = {
    'Threshold_diabetes 0.4': 0.4,
    'Threshold_diabetes 0.5': 0.5,
    'Threshold_diabetes 0.6': 0.6
}

def clasificar_y_contar_dos_grupos(prob, threshold):
    clases = []
    for p in prob:
        if p > threshold:
            clases.append("Diabetes")
        else:
            clases.append("No ident")
    clases_np = np.array(clases)
    labels, counts = np.unique(clases_np, return_counts=True)
    total = counts.sum()
    porcentaje = {label: count * 100 / total for label, count in zip(labels, counts)}
    return porcentaje

print("Comparativo de thresholds (solo Diabetes y No ident)\n")
for nombre, th in thresholds.items():
    resultados = clasificar_y_contar_dos_grupos(prob, th)
    print(f" {nombre} (t={th}):")
    for clase in ['Diabetes', 'No ident']:
        porcentaje = resultados.get(clase, 0)
        print(f"   {clase}: {porcentaje:.2f}%")
    print()

"""Como estamos en busca de un umbral para diagnóstico temprano, esto significa detectar la mayoría de los casos reales de diabetes, aunque eso implique cometer algunos errores (falsos positivos).Porque no diagnosticar a una persona que sí tiene diabetes puede traer consecuencias graves a largo plazo (ceguera, amputaciones, infartos). Un falso positivo, en cambio, solo llevará a hacer más exámenes (no pone en riesgo la vida del paciente).


Durante la evaluación de distintos umbrales, observamos que un threshold de 0.4 permite detectar 17 mujeres con diabetes, una más que con el threshold de 0.5, que identifica correctamente a 16 mujeres (44.16% vs 33.77%). Sin embargo, esta ligera ganancia en predecir verdaderos positivos viene acompañada de un aumento considerable en los falsos positivos, lo que disminuye la capacidad del modelo para distinguir correctamente a las personas no diabéticas. Es decir, se reduce la precisión y se incrementa el número de diagnósticos erróneos en personas sanas.


Por esta razón, seleccionamos un threshold de 0.5, ya que mantiene una buena capacidad para detectar casos reales de diabetes (16 verdaderos positivos) sin comprometer la seguridad diagnóstica de los pacientes normales.

<font color='056938'> **Predicciones mejor modelo con threshold de 0.5**</font>
"""

#Prediccion del mejor modelo
y_test_pred_modelo_ganador= modelo_ganador.predict(X_test)

threshold_diabetes=0.5

pred_test=(modelo_ganador.predict(X_test)>=threshold_diabetes).astype('int')
print(metrics.classification_report(y_test, pred_test))
cm=metrics.confusion_matrix(y_test,pred_test, labels=[0,1])
disp=metrics.ConfusionMatrixDisplay(cm,display_labels=['Normal', 'Diabetes'])
disp.plot()

"""**Accuracy:** El modelo clasifica correctamente el 75% de las muestras en general, es decir, acierta a predecir si una persona tiene o no diabetes en el 75% de los casos.

**Precision:** De todas las muestras que el modelo clasificó con diabetes, el 62% realmente eran diabeticas.

**Recall:**  El modelo reconoce correctamente al 64% de los pacientes con diabetes


"""