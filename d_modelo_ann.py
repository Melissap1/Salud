# -*- coding: utf-8 -*-
"""Modelo_ANN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zHulO1lVtW9NuGFDKKNdL51-6rYYacsF

# <font color='056938'> **Librerias** </font>
"""

!pip install keras-tuner

!pip install -q tensorflow

import sys
import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from google.colab import drive


#Red neuronal
from tensorflow import keras
import tensorflow as tf
from sklearn import metrics
from keras_tuner.tuners import RandomSearch
from tensorflow.keras import layers
from sklearn.metrics import accuracy_score
import keras_tuner as kt

drive.mount('/content/drive')
#Define la parte del directorio que quieres trabajar
path = "/content/drive/MyDrive/Mod2/Salud"

# Add the path to sys.path
sys.path.append(path)
os.chdir(path)

os.curdir

# Ruta al archivo
ruta = '/content/drive/MyDrive/Mod2/Salud/data/df_limpia.xlsx'

# Leer excel
df = pd.read_excel(ruta)
df

sys.path.append(path)

from b_preprocesamiento import preparar_datos #Importar funci贸n que contiene los datos de entrenamiento, test y validaci贸n

X_train, X_val, X_test, y_train, y_val, y_test = preparar_datos(df)

"""# <font color='056938'> **Redes neuronales** </font>

<font color='056938'> **1.Modelo Base: Red Neuronal Artificial (ANN)**</font>

Se selecciona una red neuronal artificial (ANN) como modelo base, ya que es especialmente adecuada para el manejo de datos tabulares.
"""

# Reproducci贸n de resultados utilizando semilla aleatoria
keras.utils.set_random_seed(42)
# Definir la semilla para numpy
# Definir la semilla para el backend random
# Definir la semilla para python

tf.random.set_seed(42)

"""Se decide usar 128 como numero m谩ximo de neuronas ya que los datos presentan una baja complejidad."""

# Definici贸n de hiperpar谩metros iniciales

ann1 = keras.models.Sequential()
# Capa de entrada
ann1.add(keras.layers.Dense(128, input_dim=X_train.shape[1], activation='tanh'))
# Capas ocultas
ann1.add(keras.layers.Dense(64, activation='relu'))
ann1.add(keras.layers.Dense(32, activation='relu'))
# Capa de salida para clasificaci贸n binaria (activaci贸n sigmoide)
ann1.add(keras.layers.Dense(1, activation='sigmoid'))

# Resumen de la arquitectura y # total de parametros
ann1.summary()

"""El optimizador seleccionado es "adam" ya que combina las ventajas de los algoritmos de gradiente descendente con momento y RMSprop, adapt谩ndose din谩micamente a la tasa de aprendizaje de cada par谩metro. Adem谩s, se usa la funci贸n de perdida "binary_crossentropy", ya que es la que se debe usar para problemas de clasificaci贸n como es el caso. Como m茅trica de rendimiento, se utiliza "Accuracy", ya que proporciona una interpretaci贸n intuitiva de cu谩n bien el modelo clasifica correctamente los datos de prueba."""

# Compilaci贸n de la ANN1 (Optimizaci贸n de la ANN)
ann1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Entrenamiento de la Red Neuronal
history = ann1.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val))

# Visualizaci贸n de las curvas de error

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Variaci贸n de la funci贸n de p茅rdida ANN1')
plt.xlabel('Epochs - Tiempo de entrenamiento')
plt.ylabel('Loss')
plt.legend(['train', 'val'])
plt.show()

# Visualizaci贸n de las curcas de la m茅trica: Accuracy

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy de la ANN1 base')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Entrenamiento', 'Validaci贸n'], loc = 'upper left')
plt

"""Dado a que se evidencia sobreajuste se realiza un modelo ANN2 donde se le aplicara regularizaci贸n L2  y otro modelo ANN3 en el cual se le aplicara Dropout. Con el fin si se evidencia alguna mejora.

<font color='056938'> **2.Modelo ANN2 con Regularizaci贸n L2**</font>

Se aplica una regularizaci贸n L2 solo a la primera capa oculta con una tasa de regularizaci贸n de 0.01.
"""

from tensorflow.keras import regularizers

ann2 = keras.models.Sequential()
# Capa de entrada
ann2.add(keras.layers.Dense(128, input_dim=X_train.shape[1], activation='tanh'))
# Capas ocultas
ann2.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l2=0.01)))
ann2.add(keras.layers.Dense(32, activation='relu'))
# Capa de salida para clasificaci贸n binaria (activaci贸n sigmoide)
ann2.add(keras.layers.Dense(1, activation='sigmoid'))

# Compilaci贸n de la ANN1 (Optimizaci贸n de la ANN)
ann2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
# Entrenamiento de la Red Neuronal
history2 = ann2.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val))

# Visualizaci贸n de las curvas de error

plt.plot(history2.history['loss'])
plt.plot(history2.history['val_loss'])
plt.title('Variaci贸n de la funci贸n de p茅rdida ANN2')
plt.xlabel('Epochs - Tiempo de entrenamiento')
plt.ylabel('Loss')
plt.legend(['train', 'val'])
plt.show()

# Visualizaci贸n de las curcas de la m茅trica: Accuracy

plt.plot(history2.history['accuracy'])
plt.plot(history2.history['val_accuracy'])
plt.title('Accuracy de la ANN2')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Entrenamiento', 'Validaci贸n'], loc = 'upper left')
plt

"""<font color='056938'> **3.Modelo ANN3 con Dropout**</font>

Se aplicar谩 Dropout con una tasa del 30% a la capa de entrada, debido a su mayor n煤mero de neuronas.

"""

ann3 = keras.models.Sequential()
# Capa de entrada
ann3.add(keras.layers.Dense(128, input_dim=X_train.shape[1], activation='tanh'))
#Dropout
ann3.add(keras.layers.Dropout(0.3))
# Capas ocultas
ann3.add(keras.layers.Dense(64, activation='relu'))
ann3.add(keras.layers.Dense(32, activation='relu'))
# Capa de salida para clasificaci贸n binaria (activaci贸n sigmoide)
ann3.add(keras.layers.Dense(1, activation='sigmoid'))

# Compilaci贸n de la ANN1 (Optimizaci贸n de la ANN)
ann3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
# Entrenamiento de la Red Neuronal
history3 = ann3.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val))

# Visualizaci贸n de las curvas de error

plt.plot(history3.history['loss'])
plt.plot(history3.history['val_loss'])
plt.title('Variaci贸n de la funci贸n de p茅rdida ANN3')
plt.xlabel('Epochs - Tiempo de entrenamiento')
plt.ylabel('Loss')
plt.legend(['train', 'val'])
plt.show()

# Visualizaci贸n de las curcas de la m茅trica: Accuracy

plt.plot(history3.history['accuracy'])
plt.plot(history3.history['val_accuracy'])
plt.title('Accuracy de la ANN3')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Entrenamiento', 'Validaci贸n'], loc = 'upper left')
plt

"""<font color='056938'> **4.Modelo ANN4: Mejor modelo encontrado Utilizando ptimizaci贸n de hiperpar谩metros**</font>

La optimizaci贸n del modelo se centr贸 en la afinaci贸n de los hiperpar谩metros m谩s influyentes en el rendimiento de la red neuronal: el n煤mero de neuronas por capa, las funciones de activaci贸n y la tasa de aprendizaje. Se exploraron diversas combinaciones de estos par谩metros con el fin de identificar la configuraci贸n 贸ptima. Considerando los resultados obtenidos en experimentos previos, se decidi贸 no incluir t茅cnicas de regularizaci贸n adicionales como L2 o Dropout, y tampoco se decidio probar varias opciones de numeros de capas, dada a que en nuestro caso el problema a resolver no presenta una complejidad excesiva, por tanto se deja la arquitectura del modelo base.
"""

# Definir la funci贸n para construir el modelo
def build_model(hp):
    model = keras.models.Sequential()

    # Capa de entrada
    model.add(keras.layers.Dense(
        units=hp.Int('units_input', min_value=32, max_value=256, step=64),  # N煤mero de neuronas
        activation=hp.Choice('activation_input', values=['relu', 'tanh']),  # Funci贸n de activaci贸n
        input_dim=X_train.shape[1]
    ))

    # Capa oculta 1
    model.add(keras.layers.Dense(
        units=hp.Int('units_hidden1', min_value=16, max_value=128, step=32),
        activation=hp.Choice('activation_hidden1', values=['relu', 'tanh'])
    ))

    # Capa oculta 2
    model.add(keras.layers.Dense(
        units=hp.Int('units_hidden2', min_value=8, max_value=64, step=16),
        activation=hp.Choice('activation_hidden2', values=['relu', 'tanh'])
    ))

    # Capa de salida
    model.add(keras.layers.Dense(1, activation='sigmoid'))  # Clasificaci贸n binaria

     # Definici贸n del compilador con optimizaci贸n del hiperpar谩metro lr
    hp_learning_rate = hp.Choice('learning_rate', values=[0.1, 0.01, 0.001, 0.0001])

    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),
        loss='binary_crossentropy',
        metrics=['accuracy']
        )

    return model

tuner = kt.RandomSearch(
    hypermodel=build_model,
    objective='val_accuracy',  # M茅trica objetivo
    max_trials=5,  # N煤mero m谩ximo de combinaciones de hiperpar谩metros
    executions_per_trial=2,  # N煤mero de ejecuciones por combinaci贸n
    directory='results_tuner',
    project_name='mujeres_diabetes'
)

# Ejecuci贸n de la b煤squeda aleatoria
tuner.search(X_train, y_train, epochs = 15, validation_data = (X_val, y_val))

# Obtener los mejores hiperpar谩metros
best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]
print("Mejores hiperpar谩metros encontrados:")
print(best_hp.values)

"""Podemos evidenciar que los hiperpar谩metros encontrados generan un modelo no tan complejo, ya que el n煤mero de neuronas escogidas son valores de no maximo 64 neuronas. Por otro lado, la tasa de arendizaje de 0.001, sugiere que los ajustes en los pesos de la red se realizan de forma gradual y cuidadosa, lo cual ayuda a evitar el riesgo de sobreajuste."""

# Reconstruir el mejor modelo
best_ANN = tuner.get_best_models(num_models=1)[0]

## Ajuste de la red neuronal con hiperpar谩metros 贸ptimos
history_4 = best_ANN.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))

# Visualizaci贸n de las curvas de error
plt.plot(history_4.history['loss'])
plt.plot(history_4.history['val_loss'])
plt.title('Variaci贸n de la funci贸n de p茅rdida - best ANN')
plt.xlabel('Epochs - Tiempo de entrenamiento')
plt.ylabel('Loss')
plt.legend(['train', 'val'])
plt.show()

# Visualizaci贸n de las curvas de Accuracy
plt.plot(history_4.history['accuracy'])
plt.plot(history_4.history['val_accuracy'])
plt.title('Variaci贸n del Accuracy - best ANN')
plt.xlabel('Epochs - Tiempo de entrenamiento')
plt.ylabel('Accuracy')
plt.legend(['train', 'val'])
plt.show()

"""Al analizar la **gr谩fica de la funci贸n de p茅rdida del mejor modelo de red neuronal (best ANN)**, observamos que a pesar de haber optimizado los hiperpar谩metros, la curva de validaci贸n muestra un aumento progresivo en lugar de disminuir a lo largo de las 茅pocas. Este comportamiento indica que el modelo est谩 sobreajust谩ndose a los datos de entrenamiento, es decir, est谩 memorizando los datos espec铆ficos del conjunto de entrenamiento en lugar de aprender las caracter铆sticas generales que le permitan generalizar a nuevos datos.

De manera similar, la **gr谩fica de Accuracy del modelo** revela que, aunque la precisi贸n en el conjunto de entrenamiento aumenta, la precisi贸n en el conjunto de validaci贸n disminuye en las 煤ltimas 茅pocas. Esta tendencia confirma el sobreajuste, ya que el modelo est谩 obteniendo un rendimiento excelente en los datos que ya ha visto (conjunto de entrenamiento), pero su desempe帽o empeora significativamente en datos no vistos (conjunto de validaci贸n).

En resumen, los resultados obtenidos sugieren que la configuraci贸n actual de hiperpar谩metros y posiblemente la arquitectura de la red no son las m谩s adecuadas para evitar el sobreajuste.

<font color='056938'> **5.Evaluaci贸n de los 4 modelos**</font>

Se evaluan los 4 modelos anteriamiente analizados, ya que en forma visual o grafica no se evidenci贸 una mejora significativa de un modelo con otro. Por tanto, para escoger el mejor modelo se evaluan con respecto a los datos de prueba.
"""

test_loss_ann1, test_acc_ann1 = ann1.evaluate(X_test, y_test)
test_loss_ann2, test_acc_ann2 = ann2.evaluate(X_test, y_test)
test_loss_ann3, test_acc_ann3 = ann3.evaluate(X_test, y_test)
test_loss_ann4, test_acc_ann4 = best_ANN.evaluate(X_test, y_test)

# Crear un diccionario con los resultados
results = {
    'Model': ['Modelo Base (ann1)', 'Modelo con Regularization L2 (ann2)', 'Modelo con Dropout (ann3)', 'Modelo optimizado (best_ann)'],
    'Test Accuracy': [test_acc_ann1, test_acc_ann2, test_acc_ann3, test_acc_ann4],
    'Test Loss': [test_loss_ann1, test_loss_ann2, test_loss_ann3, test_loss_ann4]
}

# Crear un DataFrame a partir del diccionario
df_results = pd.DataFrame(results)

# Mostrar la tabla con los resultados
df_results

"""De acuerdo con los resultados obtenidos, el modelo **ANN3** con Dropout se destaca como el mejor candidato, presentando el menor error de prueba (test loss) y la mayor precisi贸n de prueba (test accuracy) entre los modelos evaluados. Sin embargo, es importante se帽alar que el error de prueba sigue siendo considerablemente alto, superando el 50%. Este resultado sugiere que, aunque el modelo ANN3 es superior a los dem谩s en este conjunto de datos, su capacidad para generalizar a nuevos datos no vistos podr铆a ser limitada.

<font color='056938'> **An谩lisis del modelo ganador**</font>
"""

# Evaluaci贸n en el conjunto de prueba
test_loss, test_auc = best_ANN.evaluate(X_test, y_test)
print(f"\nMejor AUC on test set: {test_auc:.4f}")

####probabilidades en test #######

prob=best_ANN.predict(X_test)
sns.histplot(prob, legend=False, bins=30)
plt.title("Distribuci贸n de probabilidades en X_test")
plt.xlabel("Probabilidad de tener diabetes")

"""Se observaron agrupaciones de predicciones cercanas a 0 y a 1, lo que sugiere que el modelo tiene alta confianza en muchas de sus predicciones."""

### probabilidades en entrenamiento #####
prob1=best_ANN.predict(X_train)
sns.histplot(prob1, legend=False, bins=30)
plt.title("Distribuci贸n de probabilidades en X_train")
plt.xlabel("Probabilidad de tener diabetes")

"""Se observaron agrupaciones de predicciones cercanas a 0, lo que sugiere que el modelo tiene alta confianza en muchas de sus predicciones en los datos de entrenamento cuando no se tiene diabetes."""

threshold_diabetes=0.5

pred_train=(ann3.predict(X_train)>=threshold_diabetes).astype('int')
print(metrics.classification_report(y_train, pred_train))
cm=metrics.confusion_matrix(y_train,pred_train, labels=[0,1])
disp=metrics.ConfusionMatrixDisplay(cm,display_labels=['Normal', 'Diabetes'])
disp.plot()




pred_test=(ann3.predict(X_test)>=threshold_diabetes).astype('int')
print(metrics.classification_report(y_test, pred_test))
cm=metrics.confusion_matrix(y_test,pred_test, labels=[0,1])
disp=metrics.ConfusionMatrixDisplay(cm,display_labels=['Normal', 'Diabetes'])
disp.plot()

threshold_no_diabetes=0.4

pred_train=(ann3.predict(X_train)<=threshold_no_diabetes).astype('int')
print(metrics.classification_report(y_train, pred_train))
cm=metrics.confusion_matrix(y_train,pred_train, labels=[0,1])
disp=metrics.ConfusionMatrixDisplay(cm,display_labels=['Normal', 'Diabetes'])
disp.plot()

pred_test=(ann3.predict(X_test)<=threshold_no_diabetes).astype('int')
print(metrics.classification_report(y_test, pred_test))
cm=metrics.confusion_matrix(y_test,pred_test, labels=[0,1])
disp=metrics.ConfusionMatrixDisplay(cm,display_labels=['Normal', 'Diabetes'])
disp.plot()

threshold_diab=0.6

pred_train=(ann3.predict(X_train)>=threshold_diab).astype('int')
print(metrics.classification_report(y_train, pred_train))
cm=metrics.confusion_matrix(y_train,pred_train, labels=[0,1])
disp=metrics.ConfusionMatrixDisplay(cm,display_labels=['Normal', 'Diabetes'])
disp.plot()




pred_test=(ann3.predict(X_test)>=threshold_diab).astype('int')
print(metrics.classification_report(y_test, pred_test))
cm=metrics.confusion_matrix(y_test,pred_test, labels=[0,1])
disp=metrics.ConfusionMatrixDisplay(cm,display_labels=['Normal', 'Diabetes'])
disp.plot()

prob = ann3.predict(X_test).ravel()

thresholds = {
    'Threshold 0.4': 0.4,
    'Threshold 0.5': 0.5,
    'Threshold 0.6': 0.6
}

def clasificar_y_contar_dos_grupos(prob, threshold):
    clases = []
    for p in prob:
        if p > threshold:
            clases.append("No ident")
        else:
            clases.append("Diabetes")
    clases_np = np.array(clases)
    labels, counts = np.unique(clases_np, return_counts=True)
    total = counts.sum()
    porcentaje = {label: count * 100 / total for label, count in zip(labels, counts)}
    return porcentaje

print(" Comparativo de thresholds (solo Diabetes y No ident)\n")
for nombre, th in thresholds.items():
    resultados = clasificar_y_contar_dos_grupos(prob, th)
    print(f" {nombre} (t={th}):")
    for clase in ['Diabetes', 'No ident']:
        porcentaje = resultados.get(clase, 0)
        print(f"   {clase}: {porcentaje:.2f}%")
    print()

"""Como estamos en busca de un umbral para diagn贸stico temprano, esto significa detectar la mayor铆a de los casos reales de diabetes, aunque eso implique cometer algunos errores (falsos positivos).Porque no diagnosticar a una persona que s铆 tiene diabetes puede traer consecuencias graves a largo plazo (ceguera, amputaciones, infartos). Un falso positivo, en cambio, solo llevar谩 a hacer m谩s ex谩menes (no pone en riesgo la vida del paciente). Es por esto que definimos el threshold en 0.5 y no valores menores o mayores ya que es el que mejor predice la mayor cantidad de los que no tienen diabetes de manera acertiva y tambien predice el mayor valor de verdaderos positivos con 16 mujeres  que predice con diabetes y que si tienen diabetes.

<font color='056938'> **Predicciones mejor modelo de red neuronal: Modelo con Dropout**</font>
"""

#Prediccion del mejor modelo
y_test_pred_ann3= ann3.predict(X_test)

"""Para evaluar la capacidad del modelo de predecir correctamente si una persona tiene diabetes, se construye una matriz de confusi贸n. Dado que la red neuronal genera probabilidades de pertenecer a cada clase, se establece un umbral de 0.5: si la probabilidad predicha es superior a 0.5, se clasifica al individuo como diab茅tico (1); de lo contrario, se clasifica como no diab茅tico (0)."""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

y_test_pred_ann3= (y_test_pred_ann3 > 0.5).astype(int)  # Convertir a clases binarias

# Generar la matriz de confusi贸n
cm_test_ann = confusion_matrix(y_test, y_test_pred_ann3)

# Visualizar la matriz de confusi贸n
disp = ConfusionMatrixDisplay(confusion_matrix=cm_test_ann, display_labels=[0, 1])  # Ajustar etiquetas seg煤n las clases
disp.plot()

# Imprimir la matriz de confusi贸n
print(cm_test_ann)

tn, fp, fn, tp = cm_test_ann.ravel()

Accuracy_ANN= accuracy_score(y_test, y_test_pred_ann3)
precision_ANN = tp / (tp + fp)
recall_ANN = tp / (tp + fn)
especificidad_ANN = tn / (fp + tn)
f1_score_ANN = 2*(precision_ANN*recall_ANN)/(precision_ANN+recall_ANN)

print(f"Accuracy test: {Accuracy_ANN}")
print(f'Precision: {precision_ANN}')
print(f'Recall: {recall_ANN}')
print(f'Especificidad: {especificidad_ANN}')
print(f'F1 score: {f1_score_ANN}')

"""**Accuracy:** El modelo clasifica correctamente el 75.32% de las muestras en general, es decir, acierta a predecir si una persona tiene o no diabetes en el 75.32% de los casos.

**Precision:** De todas las muestras que el modelo clasific贸 con diabetes, el 61.54% realmente eran diabeticas.

**Recall:** El modelo identifica captura el 64% de todas las personas con diabetes en el conjunto de datos.

**Especificidad:** cuando el modelo dice que alguien no tiene diabetes, tiene raz贸n en el 80.77% de los casos.
"""

ann3.save('/content/drive/MyDrive/Mod2/Salud/salidas/best_model.keras')