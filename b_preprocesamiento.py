# -*- coding: utf-8 -*-
"""b_preprocesamiento.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14TNOWV6GBmzXNVWVuQDzULCkUqsHK7_6

# <font color='056938'> **Librerias** </font>
"""

from google.colab import drive
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

drive.mount('/content/drive')
# Ruta al archivo
ruta = '/content/drive/MyDrive/Mod2/Salud/data/df_limpia.xlsx'

# Leer excel
df = pd.read_excel(ruta)
df

"""<font color='056938'> **Separación datos de entrenaminto, validación y prueba**</font>

En la siguiente función se estandarizan las variables y se separan los datos en entrenamiento, validación y prueba.

* El conjunto de entrenamiento se utiliza para ajustar los pesos del modelo y permitir que este aprenda los patrones subyacentes en los datos.

* El conjunto de prueba (test) se reserva exclusivamente para la evaluación final del modelo, proporcionando una medición imparcial de su rendimiento en datos que no ha visto durante el proceso de entrenamiento.

* El conjunto de validación se utiliza para optimizar los hiperparámetros del modelo, permitiendo ajustar configuraciones como la tasa de aprendizaje o el número de capas en el caso de redes neuronales, sin influir en la evaluación final.

En general, se sigue una distribución de los datos en:

* 70% para entrenamiento.
* 20% para validación, con el fin de optimizar hiperparámetros.
* 10% para prueba, con el objetivo de obtener una evaluación final e imparcial del rendimiento del modelo.
"""

def preparar_datos(df):
    X = df.drop(columns=['Diagnostico'])  # Características
    y = df['Diagnostico']  # Etiqueta

    # Escalar las características
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Dividir en 70% entrenamiento y 30% (validación + prueba)
    X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, train_size=0.7, random_state=42)

    # Ahora dividir el 30% restante en 20% validación y 10% prueba
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=1/3, random_state=42)


    return X_train, X_val, X_test, y_train, y_val, y_test

X_train, X_val, X_test, y_train, y_val, y_test = preparar_datos(df)

#print(f"X_train: {X_train.shape}, y_train: {y_train.shape}")
#print(f" X_val: {X_val.shape}, y_val: {y_val.shape}")
#print(f" X_test: {X_test.shape}, y_test: {y_test.shape}")