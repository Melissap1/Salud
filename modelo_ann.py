# -*- coding: utf-8 -*-
"""Modelo_ANN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zHulO1lVtW9NuGFDKKNdL51-6rYYacsF

# <font color='056938'> **Librerias** </font>
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from google.colab import drive
import sys
import os

#Red neuronal
from tensorflow import keras
import tensorflow as tf
from keras_tuner.tuners import RandomSearch
from tensorflow.keras import layers
from sklearn.metrics import accuracy_score
import keras_tuner as kt

!pip install keras-tuner

drive.mount('/content/drive')
#Define la parte del directorio que quieres trabajar
path = "/content/drive/MyDrive/Mod2/Salud"

# Ruta al archivo
ruta = '/content/drive/MyDrive/Mod2/Salud/data/df_limpia.xlsx'

# Leer excel
df = pd.read_excel(ruta)
df

sys.path.append(path)

from b_preprocesamiento import preparar_datos #Importar función que contiene los datos de entrenamiento, test y validación

X_train, X_val, X_test, y_train, y_val, y_test = preparar_datos(df)

"""# <font color='056938'> **Redes neuronales** </font>

<font color='056938'> **1.Modelo Base: Red Neuronal Artificial (ANN)**</font>

Se selecciona una red neuronal artificial (ANN) como modelo base, ya que es especialmente adecuada para el manejo de datos tabulares.
"""

# Reproducción de resultados utilizando semilla aleatoria
keras.utils.set_random_seed(42)
# Definir la semilla para numpy
# Definir la semilla para el backend random
# Definir la semilla para python

tf.random.set_seed(42)

"""Se decide usar 128 como numero máximo de neuronas ya que los datos presentan una baja complejidad."""

# Definición de hiperparámetros iniciales

ann1 = keras.models.Sequential()
# Capa de entrada
ann1.add(keras.layers.Dense(128, input_dim=X_train.shape[1], activation='tanh'))
# Capas ocultas
ann1.add(keras.layers.Dense(64, activation='relu'))
ann1.add(keras.layers.Dense(32, activation='relu'))
# Capa de salida para clasificación binaria (activación sigmoide)
ann1.add(keras.layers.Dense(1, activation='sigmoid'))

# Resumen de la arquitectura y # total de parametros
ann1.summary()

"""El optimizador seleccionado es "adam" ya que combina las ventajas de los algoritmos de gradiente descendente con momento y RMSprop, adaptándose dinámicamente a la tasa de aprendizaje de cada parámetro. Además, se usa la función de perdida "binary_crossentropy", ya que es la que se debe usar para problemas de clasificación como es el caso. Como métrica de rendimiento, se utiliza "Accuracy", ya que proporciona una interpretación intuitiva de cuán bien el modelo clasifica correctamente los datos de prueba."""

# Compilación de la ANN1 (Optimización de la ANN)
ann1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Entrenamiento de la Red Neuronal
history = ann1.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val))

# Visualización de las curvas de error

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Variación de la función de pérdida ANN1')
plt.xlabel('Epochs - Tiempo de entrenamiento')
plt.ylabel('Loss')
plt.legend(['train', 'val'])
plt.show()

# Visualización de las curcas de la métrica: Accuracy

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy de la ANN1 base')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Entrenamiento', 'Validación'], loc = 'upper left')
plt

"""Dado a que se evidencia sobreajuste se realiza un modelo ANN2 donde se le aplicara regularización L2  y otro modelo ANN3 en el cual se le aplicara Dropout. Con el fin si se evidencia alguna mejora.

<font color='056938'> **2.Modelo ANN2 con Regularización L2**</font>

Se aplica una regularización L2 solo a la primera capa oculta con una tasa de regularización de 0.01.
"""

from tensorflow.keras import regularizers

ann2 = keras.models.Sequential()
# Capa de entrada
ann2.add(keras.layers.Dense(128, input_dim=X_train.shape[1], activation='tanh'))
# Capas ocultas
ann2.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l2=0.01)))
ann2.add(keras.layers.Dense(32, activation='relu'))
# Capa de salida para clasificación binaria (activación sigmoide)
ann2.add(keras.layers.Dense(1, activation='sigmoid'))

# Compilación de la ANN1 (Optimización de la ANN)
ann2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
# Entrenamiento de la Red Neuronal
history2 = ann2.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val))

# Visualización de las curvas de error

plt.plot(history2.history['loss'])
plt.plot(history2.history['val_loss'])
plt.title('Variación de la función de pérdida ANN2')
plt.xlabel('Epochs - Tiempo de entrenamiento')
plt.ylabel('Loss')
plt.legend(['train', 'val'])
plt.show()

# Visualización de las curcas de la métrica: Accuracy

plt.plot(history2.history['accuracy'])
plt.plot(history2.history['val_accuracy'])
plt.title('Accuracy de la ANN2')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Entrenamiento', 'Validación'], loc = 'upper left')
plt

"""<font color='056938'> **3.Modelo ANN3 con Dropout**</font>

Se aplicará Dropout con una tasa del 30% a la capa de entrada, debido a su mayor número de neuronas.

"""

ann3 = keras.models.Sequential()
# Capa de entrada
ann3.add(keras.layers.Dense(128, input_dim=X_train.shape[1], activation='tanh'))
#Dropout
ann3.add(keras.layers.Dropout(0.3))
# Capas ocultas
ann3.add(keras.layers.Dense(64, activation='relu'))
ann3.add(keras.layers.Dense(32, activation='relu'))
# Capa de salida para clasificación binaria (activación sigmoide)
ann3.add(keras.layers.Dense(1, activation='sigmoid'))

# Compilación de la ANN1 (Optimización de la ANN)
ann3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
# Entrenamiento de la Red Neuronal
history3 = ann3.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val))

# Visualización de las curvas de error

plt.plot(history3.history['loss'])
plt.plot(history3.history['val_loss'])
plt.title('Variación de la función de pérdida ANN3')
plt.xlabel('Epochs - Tiempo de entrenamiento')
plt.ylabel('Loss')
plt.legend(['train', 'val'])
plt.show()

# Visualización de las curcas de la métrica: Accuracy

plt.plot(history3.history['accuracy'])
plt.plot(history3.history['val_accuracy'])
plt.title('Accuracy de la ANN3')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Entrenamiento', 'Validación'], loc = 'upper left')
plt

"""<font color='056938'> **4.Modelo ANN4: Mejor modelo encontrado Utilizando Óptimización de hiperparámetros**</font>

La optimización del modelo se centró en la afinación de los hiperparámetros más influyentes en el rendimiento de la red neuronal: el número de neuronas por capa, las funciones de activación y la tasa de aprendizaje. Se exploraron diversas combinaciones de estos parámetros con el fin de identificar la configuración óptima. Considerando los resultados obtenidos en experimentos previos, se decidió no incluir técnicas de regularización adicionales como L2 o Dropout, y tampoco se decidio probar varias opciones de numeros de capas, dada a que en nuestro caso el problema a resolver no presenta una complejidad excesiva, por tanto se deja la arquitectura del modelo base.
"""

# Definir la función para construir el modelo
def build_model(hp):
    model = keras.models.Sequential()

    # Capa de entrada
    model.add(keras.layers.Dense(
        units=hp.Int('units_input', min_value=32, max_value=256, step=64),  # Número de neuronas
        activation=hp.Choice('activation_input', values=['relu', 'tanh']),  # Función de activación
        input_dim=X_train.shape[1]
    ))

    # Capa oculta 1
    model.add(keras.layers.Dense(
        units=hp.Int('units_hidden1', min_value=16, max_value=128, step=32),
        activation=hp.Choice('activation_hidden1', values=['relu', 'tanh'])
    ))

    # Capa oculta 2
    model.add(keras.layers.Dense(
        units=hp.Int('units_hidden2', min_value=8, max_value=64, step=16),
        activation=hp.Choice('activation_hidden2', values=['relu', 'tanh'])
    ))

    # Capa de salida
    model.add(keras.layers.Dense(1, activation='sigmoid'))  # Clasificación binaria

     # Definición del compilador con optimización del hiperparámetro lr
    hp_learning_rate = hp.Choice('learning_rate', values=[0.1, 0.01, 0.001, 0.0001])

    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),
        loss='binary_crossentropy',
        metrics=['accuracy']
        )

    return model

tuner = kt.RandomSearch(
    hypermodel=build_model,
    objective='val_accuracy',  # Métrica objetivo
    max_trials=5,  # Número máximo de combinaciones de hiperparámetros
    executions_per_trial=2,  # Número de ejecuciones por combinación
    directory='results_tuner',
    project_name='mujeres_diabetes'
)

# Ejecución de la búsqueda aleatoria
tuner.search(X_train, y_train, epochs = 15, validation_data = (X_val, y_val))

# Obtener los mejores hiperparámetros
best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]
print("Mejores hiperparámetros encontrados:")
print(best_hp.values)

"""Podemos evidenciar que los hiperparámetros encontrados generan un modelo no tan complejo, ya que el número de neuronas escogidas son valores de no maximo 64 neuronas. Por otro lado, la tasa de arendizaje de 0.001, sugiere que los ajustes en los pesos de la red se realizan de forma gradual y cuidadosa, lo cual ayuda a evitar el riesgo de sobreajuste."""

# Reconstruir el mejor modelo
best_ANN = tuner.get_best_models(num_models=1)[0]

## Ajuste de la red neuronal con hiperparámetros óptimos
history_4 = best_ANN.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))

# Visualización de las curvas de error
plt.plot(history_4.history['loss'])
plt.plot(history_4.history['val_loss'])
plt.title('Variación de la función de pérdida - best ANN')
plt.xlabel('Epochs - Tiempo de entrenamiento')
plt.ylabel('Loss')
plt.legend(['train', 'val'])
plt.show()

# Visualización de las curvas de Accuracy
plt.plot(history_4.history['accuracy'])
plt.plot(history_4.history['val_accuracy'])
plt.title('Variación del Accuracy - best ANN')
plt.xlabel('Epochs - Tiempo de entrenamiento')
plt.ylabel('Accuracy')
plt.legend(['train', 'val'])
plt.show()

"""Al analizar la **gráfica de la función de pérdida del mejor modelo de red neuronal (best ANN)**, observamos que a pesar de haber optimizado los hiperparámetros, la curva de validación muestra un aumento progresivo en lugar de disminuir a lo largo de las épocas. Este comportamiento indica que el modelo está sobreajustándose a los datos de entrenamiento, es decir, está memorizando los datos específicos del conjunto de entrenamiento en lugar de aprender las características generales que le permitan generalizar a nuevos datos.

De manera similar, la **gráfica de Accuracy del modelo** revela que, aunque la precisión en el conjunto de entrenamiento aumenta, la precisión en el conjunto de validación disminuye en las últimas épocas. Esta tendencia confirma el sobreajuste, ya que el modelo está obteniendo un rendimiento excelente en los datos que ya ha visto (conjunto de entrenamiento), pero su desempeño empeora significativamente en datos no vistos (conjunto de validación).

En resumen, los resultados obtenidos sugieren que la configuración actual de hiperparámetros y posiblemente la arquitectura de la red no son las más adecuadas para evitar el sobreajuste.

<font color='056938'> **5.Evaluación de los 4 modelos**</font>

Se evaluan los 4 modelos anteriamiente analizados, ya que en forma visual o grafica no se evidenció una mejora significativa de un modelo con otro. Por tanto, para escoger el mejor modelo se evaluan con respecto a los datos de prueba.
"""

test_loss_ann1, test_acc_ann1 = ann1.evaluate(X_test, y_test)
test_loss_ann2, test_acc_ann2 = ann2.evaluate(X_test, y_test)
test_loss_ann3, test_acc_ann3 = ann3.evaluate(X_test, y_test)
test_loss_ann4, test_acc_ann4 = best_ANN.evaluate(X_test, y_test)

# Crear un diccionario con los resultados
results = {
    'Model': ['Modelo Base (ann1)', 'Modelo con Regularization L2 (ann2)', 'Modelo con Dropout (ann3)', 'Modelo optimizado (best_ann)'],
    'Test Accuracy': [test_acc_ann1, test_acc_ann2, test_acc_ann3, test_acc_ann4],
    'Test Loss': [test_loss_ann1, test_loss_ann2, test_loss_ann3, test_loss_ann4]
}

# Crear un DataFrame a partir del diccionario
df_results = pd.DataFrame(results)

# Mostrar la tabla con los resultados
df_results

"""De acuerdo con los resultados obtenidos, el modelo **ANN3** con Dropout se destaca como el mejor candidato, presentando el menor error de prueba (test loss) y la mayor precisión de prueba (test accuracy) entre los modelos evaluados. Sin embargo, es importante señalar que el error de prueba sigue siendo considerablemente alto, superando el 50%. Este resultado sugiere que, aunque el modelo ANN3 es superior a los demás en este conjunto de datos, su capacidad para generalizar a nuevos datos no vistos podría ser limitada.

<font color='056938'> **Predicciones mejor modelo de red neuronal: Modelo con Dropout**</font>
"""

#Prediccion del mejor modelo
y_test_pred_ann3= ann3.predict(X_test)

"""Para evaluar la capacidad del modelo de predecir correctamente si una persona tiene diabetes, se construye una matriz de confusión. Dado que la red neuronal genera probabilidades de pertenecer a cada clase, se establece un umbral de 0.5: si la probabilidad predicha es superior a 0.5, se clasifica al individuo como diabético (1); de lo contrario, se clasifica como no diabético (0)."""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

y_test_pred_ann3= (y_test_pred_ann3 > 0.5).astype(int)  # Convertir a clases binarias

# Generar la matriz de confusión
cm_test_ann = confusion_matrix(y_test, y_test_pred_ann3)

# Visualizar la matriz de confusión
disp = ConfusionMatrixDisplay(confusion_matrix=cm_test_ann, display_labels=[0, 1])  # Ajustar etiquetas según las clases
disp.plot()

# Imprimir la matriz de confusión
print(cm_test_ann)

tn, fp, fn, tp = cm_test_ann.ravel()

Accuracy_ANN= accuracy_score(y_test, y_test_pred_ann3)
precision_ANN = tp / (tp + fp)
recall_ANN = tp / (tp + fn)
especificidad_ANN = tn / (fp + tn)
f1_score_ANN = 2*(precision_ANN*recall_ANN)/(precision_ANN+recall_ANN)

print(f"Accuracy test: {Accuracy_ANN}")
print(f'Precision: {precision_ANN}')
print(f'Recall: {recall_ANN}')
print(f'Especificidad: {especificidad_ANN}')
print(f'F1 score: {f1_score_ANN}')

"""**Accuracy:** El modelo clasifica correctamente el 75.32% de las muestras en general, es decir, acierta a predecir si una persona tiene o no diabetes en el 75.32% de los casos.

**Precision:** De todas las muestras que el modelo clasificó con diabetes, el 61.54% realmente eran diabeticas.

**Recall:** El modelo identifica captura el 64% de todas las personas con diabetes en el conjunto de datos.

**Especificidad:** cuando el modelo dice que alguien no tiene diabetes, tiene razón en el 80.77% de los casos.

"""